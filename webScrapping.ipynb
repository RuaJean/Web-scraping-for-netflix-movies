{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "0ps91OXwM8De",
        "outputId": "9d60767c-a1cb-4833-f872-d97d5f17bff4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[INFO] Scrapeando la página 1...\n",
            "[WARNING] Error 429: Too Many Requests. Reintentando en 5 segundos... (Intento 1/5)\n"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[12], line 139\u001b[0m\n\u001b[1;32m    136\u001b[0m url \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhttps://www.filmaffinity.com/es/category.php?id=new_netflix&page=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpagina\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    137\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m[INFO] Scrapeando la página \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpagina\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 139\u001b[0m enlaces_peliculas \u001b[38;5;241m=\u001b[39m \u001b[43mobtener_enlaces_peliculas\u001b[49m\u001b[43m(\u001b[49m\u001b[43murl\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    140\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m enlaces_peliculas:\n\u001b[1;32m    141\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m[INFO] No hay más películas.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
            "Cell \u001b[0;32mIn[12], line 48\u001b[0m, in \u001b[0;36mobtener_enlaces_peliculas\u001b[0;34m(url)\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mobtener_enlaces_peliculas\u001b[39m(url):\n\u001b[0;32m---> 48\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[43mrealizar_solicitud\u001b[49m\u001b[43m(\u001b[49m\u001b[43murl\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     49\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m response:\n\u001b[1;32m     50\u001b[0m         soup \u001b[38;5;241m=\u001b[39m BeautifulSoup(response\u001b[38;5;241m.\u001b[39mtext, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhtml.parser\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
            "Cell \u001b[0;32mIn[12], line 32\u001b[0m, in \u001b[0;36mrealizar_solicitud\u001b[0;34m(url, intentos, max_reintentos, tiempo_espera)\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m intentos \u001b[38;5;241m<\u001b[39m max_reintentos:\n\u001b[1;32m     31\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m[WARNING] Error 429: Too Many Requests. Reintentando en \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtiempo_espera\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m segundos... (Intento \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mintentos\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmax_reintentos\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m)\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 32\u001b[0m     \u001b[43mtime\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msleep\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtiempo_espera\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     33\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m realizar_solicitud(url, intentos \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m, max_reintentos, tiempo_espera)\n\u001b[1;32m     34\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "import time\n",
        "import random\n",
        "import csv\n",
        "import re\n",
        "\n",
        "# Definimos un header con el User-Agent de una Mac para evitar baneos\n",
        "user_agents = [\n",
        "    'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/93.0.4577.63 Safari/537.36',\n",
        "    'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36',\n",
        "    'Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.114 Safari/537.36',\n",
        "    'Mozilla/5.0 (iPhone; CPU iPhone OS 14_6 like Mac OS X) AppleWebKit/605.1.15 (KHTML, like Gecko) Version/14.0 Mobile/15E148 Safari/604.1'\n",
        "]\n",
        "\n",
        "# Función para obtener headers aleatorios\n",
        "def obtener_headers():\n",
        "    headers = {\n",
        "        'User-Agent': random.choice(user_agents)\n",
        "    }\n",
        "    return headers\n",
        "\n",
        "# Función para realizar la solicitud con manejo de reintentos\n",
        "def realizar_solicitud(url, intentos=0, max_reintentos=5, tiempo_espera=5):\n",
        "    try:\n",
        "        response = requests.get(url, headers=obtener_headers())\n",
        "        \n",
        "        # Si el código de estado es 429, esperar y reintentar\n",
        "        if response.status_code == 429:\n",
        "            if intentos < max_reintentos:\n",
        "                print(f\"[WARNING] Error 429: Too Many Requests. Reintentando en {tiempo_espera} segundos... (Intento {intentos+1}/{max_reintentos})\")\n",
        "                time.sleep(tiempo_espera)\n",
        "                return realizar_solicitud(url, intentos + 1, max_reintentos, tiempo_espera)\n",
        "            else:\n",
        "                print(f\"[ERROR] Se superó el límite de reintentos para la URL: {url}\")\n",
        "                return None\n",
        "        elif response.status_code == 200:\n",
        "            return response\n",
        "        else:\n",
        "            print(f\"[ERROR] Código de estado {response.status_code} para la URL: {url}\")\n",
        "            return None\n",
        "    except Exception as e:\n",
        "        print(f\"[ERROR] Ocurrió un error al hacer la solicitud: {str(e)}\")\n",
        "        return None\n",
        "\n",
        "# Función para obtener los títulos y los enlaces de las películas en cada página\n",
        "def obtener_enlaces_peliculas(url):\n",
        "    response = realizar_solicitud(url)\n",
        "    if response:\n",
        "        soup = BeautifulSoup(response.text, 'html.parser')\n",
        "        movie_links = []\n",
        "        movie_titles = soup.find_all('div', class_='movie-title')\n",
        "\n",
        "        if not movie_titles:\n",
        "            print(f\"[DEBUG] No se encontraron películas en la URL: {url}\")\n",
        "            return []\n",
        "\n",
        "        for title in movie_titles:\n",
        "            a_tag = title.find('a')\n",
        "            if a_tag:\n",
        "                enlace = a_tag.get('href')\n",
        "                nombre = a_tag.get('title').strip()\n",
        "                if not enlace.startswith('https'):\n",
        "                    enlace = f\"https://www.filmaffinity.com{enlace}\"\n",
        "                movie_links.append({'name': nombre, 'link': enlace})\n",
        "        return movie_links\n",
        "    else:\n",
        "        return []\n",
        "\n",
        "# Función para obtener la información de la película con reintentos\n",
        "def obtener_criticas(url_pelicula):\n",
        "    response = realizar_solicitud(url_pelicula)\n",
        "    if response:\n",
        "        soup = BeautifulSoup(response.text, 'html.parser')\n",
        "        movie_info = soup.find('dl', class_='movie-info')\n",
        "\n",
        "        if movie_info:\n",
        "            original_title = movie_info.find('dt', text='Título original').find_next_sibling('dd').get_text(strip=True) if movie_info.find('dt', text='Título original') else None\n",
        "            year = movie_info.find('dt', text='Año').find_next_sibling('dd').get_text(strip=True) if movie_info.find('dt', text='Año') else None\n",
        "            duration = movie_info.find('dt', text='Duración').find_next_sibling('dd').get_text(strip=True) if movie_info.find('dt', text='Duración') else None\n",
        "            country = movie_info.find('dt', text='País').find_next_sibling('dd').get_text(strip=True) if movie_info.find('dt', text='País') else None\n",
        "            genre = movie_info.find('dt', text='Género').find_next_sibling('dd').get_text(strip=True) if movie_info.find('dt', text='Género') else None\n",
        "\n",
        "            review_container = soup.find('div', id='review-container')\n",
        "            if review_container:\n",
        "                reviews_box = review_container.find('div', id='movie-reviews-box')\n",
        "                if reviews_box:\n",
        "                    a_tag = reviews_box.find('a', text=lambda t: 'críticas' in t.lower())\n",
        "                    if a_tag:\n",
        "                        href_reviews = a_tag.get('href')\n",
        "                        review_count = reviews_box.get_text(strip=True).split()[0]\n",
        "\n",
        "                        if not href_reviews.startswith('https'):\n",
        "                            href_reviews = f\"https://www.filmaffinity.com{href_reviews}\"\n",
        "\n",
        "                        return {\n",
        "                            'original_title': original_title,\n",
        "                            'year': year,\n",
        "                            'duration': duration,\n",
        "                            'country': country,\n",
        "                            'genre': genre,\n",
        "                            'reviews_link': href_reviews,\n",
        "                            'reviews_count': review_count\n",
        "                        }\n",
        "\n",
        "            return {\n",
        "                'original_title': original_title,\n",
        "                'year': year,\n",
        "                'duration': duration,\n",
        "                'country': country,\n",
        "                'genre': genre,\n",
        "                'reviews_link': None,\n",
        "                'reviews_count': '0'\n",
        "            }\n",
        "        else:\n",
        "            print(f\"[WARNING] No se encontró 'movie-info' en la página de la película: {url_pelicula}\")\n",
        "            return None\n",
        "    else:\n",
        "        return None\n",
        "\n",
        "# Función para limpiar el texto de reviews_count\n",
        "def limpiar_reviews_count(review_count):\n",
        "    match = re.search(r'\\d+', review_count)\n",
        "    return match.group(0) if match else '0'\n",
        "\n",
        "# Bucle para iterar sobre la paginación de las películas\n",
        "pagina = 1\n",
        "csv_filename = 'movies_and_reviews.csv'\n",
        "\n",
        "with open(csv_filename, mode='w', newline='', encoding='utf-8') as file:\n",
        "    writer = csv.writer(file)\n",
        "    writer.writerow(['Movie', 'Movie Link', 'Year', 'Duration', 'Country', 'Genre', 'Reviews Link', 'Number of Reviews', 'User', 'Score', 'Review Text'])\n",
        "\n",
        "while True:\n",
        "    try:\n",
        "        url = f\"https://www.filmaffinity.com/es/category.php?id=new_netflix&page={pagina}\"\n",
        "        print(f\"[INFO] Scrapeando la página {pagina}...\")\n",
        "\n",
        "        enlaces_peliculas = obtener_enlaces_peliculas(url)\n",
        "        if not enlaces_peliculas:\n",
        "            print(\"[INFO] No hay más películas.\")\n",
        "            break\n",
        "\n",
        "        for pelicula in enlaces_peliculas:\n",
        "            print(f\"[INFO] Procesando película: {pelicula['name']} - Enlace: {pelicula['link']}\")\n",
        "\n",
        "            criticas_info = obtener_criticas(pelicula['link'])\n",
        "            if criticas_info:\n",
        "                pelicula.update(criticas_info)\n",
        "                pelicula['reviews_count'] = limpiar_reviews_count(pelicula['reviews_count'])\n",
        "\n",
        "                detalles_criticas = []\n",
        "                if criticas_info['reviews_link']:\n",
        "                    detalles_criticas = obtener_detalles_criticas(criticas_info['reviews_link'])\n",
        "\n",
        "                with open(csv_filename, mode='a', newline='', encoding='utf-8') as file:\n",
        "                    writer = csv.writer(file)\n",
        "                    if detalles_criticas:\n",
        "                        for critica in detalles_criticas:\n",
        "                            writer.writerow([\n",
        "                                pelicula['name'],\n",
        "                                pelicula['link'],\n",
        "                                pelicula['year'],\n",
        "                                pelicula['duration'],\n",
        "                                pelicula['country'],\n",
        "                                pelicula['genre'],\n",
        "                                pelicula['reviews_link'],\n",
        "                                pelicula['reviews_count'],\n",
        "                                critica['user'],\n",
        "                                critica['score'],\n",
        "                                critica['text']\n",
        "                            ])\n",
        "                    else:\n",
        "                        writer.writerow([\n",
        "                            pelicula['name'],\n",
        "                            pelicula['link'],\n",
        "                            pelicula['year'],\n",
        "                            pelicula['duration'],\n",
        "                            pelicula['country'],\n",
        "                            pelicula['genre'],\n",
        "                            pelicula['reviews_link'],\n",
        "                            pelicula['reviews_count'],\n",
        "                            None, None, None\n",
        "                        ])\n",
        "\n",
        "        pagina += 1\n",
        "        time.sleep(0.5)\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"[ERROR] Ocurrió un error en el bucle principal: {str(e)}\")\n",
        "        break\n",
        "\n",
        "print(f\"[INFO] Proceso completado. Datos guardados en {csv_filename}\")\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.1"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
